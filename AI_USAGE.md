# AI-Assisted Development Workflow

**Author:** Muhammad Idrees

This document details how I used AI throughout this project, showcasing effective prompting strategies and quality control measures.

---

## Philosophy: AI as a Pair Programmer

**Core Principle:** AI accelerates velocity without reducing quality.

**My Role:**
- Define architecture and component APIs
- Make trade-off decisions
- Review and refine generated code
- Adjust UX details and styling
- Own the final product

**AI's Role:**
- Generate boilerplate and repetitive code
- Suggest patterns and best practices
- Accelerate UI component creation
- Provide implementation examples

**What AI Did NOT Do:**
- âŒ Decide architectural patterns (I chose Server Components, URL state, folder structure)
- âŒ Design the component APIs (I defined how `CandidateCard` and `SortControls` work)
- âŒ Finalize UI/UX decisions (I adjusted colors, spacing, and interactions)
- âŒ Replace reasoning (I debugged logic and validated correctness)

---

## Workflow Stages

### Stage 1: Architecture Planning (Human-Led)

**My Process:**
1. Read the assessment requirements
2. Sketched folder structure on paper
3. Decided on key patterns:
   - Server Components first
   - URL-based sorting
   - Mock AI with production-ready interface
4. Wrote high-level component list

**AI Used:** None at this stage. Pure architectural thinking.

**Time:** ~20 minutes

---

### Stage 2: Project Scaffolding (AI-Assisted)

**My Prompt:**
```
Scaffold a Next.js 15 project with:
- App Router structure
- /candidates route with [id] dynamic route
- /types/index.ts with Candidate interface
- /lib/data/candidates.ts with mock data (8 candidates)
- Basic layout with Tailwind CSS

Do not add UI components yet, just structure.
```

**What AI Generated:**
- Folder structure
- TypeScript interfaces
- Mock candidate data (names, roles, skills)
- Basic Next.js config files

**What I Modified:**
- Refined `Candidate` interface to include `avatar` field
- Adjusted mock data to have realistic experience ranges (1-15 years)
- Added more diverse skill sets to candidates

**Time Saved:** ~30 minutes (would've been tedious manual setup)

---

### Stage 3: Utility Functions (AI-Assisted)

**My Prompt:**
```
Create a pure function to sort candidates:
- Input: Candidate[], SortOption ('name-asc' | 'experience-desc')
- Output: Sorted Candidate[]
- Use localeCompare for names
- Add JSDoc comments
```

**What AI Generated:**
```ts
export function sortCandidates(
  candidates: Candidate[],
  sortBy: SortOption
): Candidate[] {
  return [...candidates].sort((a, b) => {
    if (sortBy === 'name-asc') {
      return a.name.localeCompare(b.name)
    }
    return b.experience - a.experience
  })
}
```

**What I Modified:**
- Added edge case handling for equal experience values
- Verified immutability (AI correctly used `[...candidates]` spread)

**Time Saved:** ~10 minutes

---

### Stage 4: UI Components (AI-Accelerated)

**My Strategy:** Generate basic structure, then refine styling and behavior.

#### Example: Candidate Card Component

**My Initial Prompt:**
```
Create a CandidateCard component:
- Props: candidate (Candidate), showActions (boolean)
- Layout: Card with avatar, name, role, experience, skills
- Use shadcn Card, Badge components
- Skills as badge array
- "View Details" button if showActions=true
```

**What AI Generated:**
- Basic component structure
- Correct shadcn imports
- Layout with flexbox
- Props interface

**What I Refined (Round 1):**
- Changed from props to compositional API:
  ```tsx
  // Before (AI generated)
  <CandidateCard candidate={c} showActions={true} />
  
  // After (my decision)
  <CandidateCard>
    <CandidateCard.Header name={c.name} role={c.role} />
    <CandidateCard.Skills skills={c.skills} />
    <CandidateCard.Actions>
      <Button>View Details</Button>
    </CandidateCard.Actions>
  </CandidateCard>
  ```

**My Follow-Up Prompt:**
```
Refactor CandidateCard to use compound components pattern.
Export CandidateCard with Header, Skills, Actions as nested components.
```

**What AI Generated:**
- Compound component structure
- Correct TypeScript for nested components

**What I Refined (Round 2):**
- Adjusted spacing between sections (from `gap-2` to `gap-4`)
- Changed skills badge variant from `secondary` to `outline`
- Added `text-balance` to name for better line breaks
- Fixed avatar fallback to use initials

**Time Saved:** ~40 minutes (component structure generated quickly, I focused on polish)

---

### Stage 5: AI Mock Implementation (AI-Assisted with Heavy Review)

**My Prompt:**
```
Create lib/ai/generate-strengths.ts:
- Export async function generateStrengths(candidateId: string): Promise<string[]>
- Use a mock map with predefined strengths
- Add 500ms delay to simulate API call
- Include JSDoc explaining this is a mock
- Add comment showing how to swap for real API
```

**What AI Generated:**
```ts
const MOCK_STRENGTHS_MAP: Record<string, string[]> = {
  '1': ['Strong React expertise', 'Team leadership'],
  // ... more
}

export async function generateStrengths(candidateId: string) {
  await new Promise(resolve => setTimeout(resolve, 500))
  return MOCK_STRENGTHS_MAP[candidateId] ?? ['Adaptable', 'Team player']
}
```

**What I Modified:**
- Made strengths more specific and realistic ("React expertise" â†’ "Built scalable React apps with 100k+ users")
- Added fallback strengths that are more meaningful
- Added detailed comment block showing OpenAI integration example
- Ensured TypeScript strict mode compliance

**Critical Decision (Mine):** Kept the function signature production-ready so UI components don't need changes when switching to real AI.

**Time Saved:** ~20 minutes

---

### Stage 6: Sorting & URL State (Hybrid Approach)

**My Decision:** Use URL search params for sort state.

**My Prompt:**
```
Create SortControls component:
- Client component (use client directive)
- Use useSearchParams and useRouter from next/navigation
- Two buttons: "Name (A-Z)" and "Experience (High-Low)"
- Update URL with ?sort=name-asc or ?sort=experience-desc
- Highlight active sort option
```

**What AI Generated:**
- Correct Next.js 15 hooks usage
- URL manipulation logic
- Button group with active states

**What I Debugged:**
- AI initially used `router.push()` which caused full page reload
- I changed to `router.replace()` for smoother transitions
- Added `scroll: false` option to prevent scroll jump

**My Fix:**
```tsx
// AI generated
router.push(`/candidates?sort=${newSort}`)

// My improvement
router.replace(`/candidates?sort=${newSort}`, { scroll: false })
```

**Time Saved:** ~15 minutes (AI got me 80% there, I refined the UX)

---

### Stage 7: Styling & Polish (Mostly Human)

**What I Did Manually:**
- Adjusted color palette (changed from AI's blue theme to emerald)
- Fine-tuned spacing throughout (gap values, padding)
- Added hover states and transitions
- Improved responsive breakpoints
- Added `text-balance` and `leading-relaxed` for readability

**AI Used:** None. Visual polish requires human judgment.

**Time:** ~45 minutes

---

## Prompting Strategies

### 1. **Incremental Prompts > Mega Prompts**

**Bad Prompt:**
```
Build a complete candidate management system with list view, 
detail pages, sorting, filtering, AI strengths, authentication, 
and database integration.
```

**Why Bad:** Too much at once. AI will make assumptions and you lose control.

**Good Approach:**
```
1. "Scaffold the project structure"
2. "Add mock data and types"
3. "Create CandidateCard component"
4. "Add sorting logic"
5. "Add AI strengths mock"
```

**Result:** I stay in control of each piece and can course-correct early.

---

### 2. **Specify Constraints Explicitly**

**Weak Prompt:**
```
Make a candidate card component
```

**Strong Prompt:**
```
Create a CandidateCard component:
- Use TypeScript
- Use shadcn Card component (don't create from scratch)
- Use Lucide icons
- Max 3 skills shown (then "+X more")
- Add hover effect
```

**Result:** AI doesn't waste time generating custom card implementations.

---

### 3. **Request Explanations for Learning**

**Example:**
```
Why did you use useRouter instead of window.location for URL changes?
```

**AI Response:**
```
useRouter from next/navigation preserves client-side navigation,
doesn't trigger full page reload, maintains scroll position...
```

**Value:** I learned Next.js patterns while building.

---

### 4. **Ask for Alternatives**

**Example:**
```
You used useState for sort state. What are pros/cons vs URL params?
```

**AI Response:**
```
useState:
+ Simpler implementation
- Loses state on refresh
- Not shareable

URL params:
+ Shareable links
+ Persists on refresh
- Slightly more complex
```

**Result:** I made informed decision to use URL params.

---

## Quality Control Measures

### 1. **Code Review Checklist**

After every AI generation, I checked:
- âœ… TypeScript errors resolved
- âœ… Imports correct and used
- âœ… No unused variables
- âœ… Consistent naming conventions
- âœ… Accessibility (alt text, ARIA labels)
- âœ… Performance (unnecessary re-renders)

### 2. **Manual Testing**

I tested every feature AI generated:
- Clicked every button
- Checked responsive behavior on mobile
- Verified sorting logic with console.logs
- Tested edge cases (no skills, long names)

### 3. **Refactoring AI Code**

**Example:** AI generated inline styles:
```tsx
<div style={{ padding: '16px', margin: '8px' }}>
```

**I refactored to Tailwind:**
```tsx
<div className="p-4 m-2">
```

**Why:** Consistency with project conventions.

---

## Metrics

| Task | Time with AI | Estimated Time Without AI | Savings |
|------|-------------|---------------------------|---------|
| Project scaffolding | 15 min | 45 min | 30 min |
| Type definitions | 5 min | 15 min | 10 min |
| Mock data generation | 10 min | 30 min | 20 min |
| Utility functions | 10 min | 20 min | 10 min |
| UI components (initial) | 30 min | 90 min | 60 min |
| AI mock implementation | 15 min | 30 min | 15 min |
| **Total** | **85 min** | **230 min** | **145 min** |

**Note:** These don't include refinement time (styling, testing, debugging) which was similar with/without AI.

**Net Result:** AI saved ~2.5 hours on boilerplate, which I reinvested in polish and documentation.

---

## What I Learned

### 1. **AI is Best at Structure, Humans at Nuance**

AI excels at:
- Generating file structures
- Creating TypeScript interfaces
- Suggesting common patterns

Humans are better at:
- UX micro-interactions
- Performance optimization
- Edge case handling
- Design consistency

### 2. **Prompting is a Skill**

Early prompts were vague and required multiple iterations. By the end, I learned to:
- Specify technologies explicitly
- Provide examples of desired output
- Break complex tasks into steps

### 3. **AI Exposes Knowledge Gaps**

When AI generated Next.js code I didn't fully understand, I asked follow-up questions. This turned coding into active learning.

---

## Tools Used

| Tool | Purpose | Usage Frequency |
|------|---------|-----------------|
| v0 by Vercel | Component generation, Next.js patterns | High |
| Claude/ChatGPT | Architecture discussion, debugging | Medium |
| GitHub Copilot | Inline autocomplete | High |
| Cursor AI | Code explanation, refactoring | Medium |

---

## Conclusion

**AI Usage Summary:**
- ðŸš€ Accelerated boilerplate by ~60%
- ðŸ§  Maintained full architectural control
- âœ… Reviewed and refined every AI output
- ðŸ“š Used AI for learning, not just code generation

**Key Takeaway:** AI is a force multiplier when you know what you want to build. It's not a replacement for engineering judgment.

---

**Questions?** Happy to discuss my workflow in detail!
